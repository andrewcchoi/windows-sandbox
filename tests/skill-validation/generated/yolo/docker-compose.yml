# ============================================================================
# MASTER DOCKER COMPOSE - All Services Kitchen Sink
# ============================================================================
# This file contains ALL possible services for the Claude Code Sandbox Plugin.
# Skills strip unused sections based on user selections.
#
# Section markers: # ===SECTION_START:name=== / # ===SECTION_END:name===
#
# Variables to replace:
#   demo-app - Project identifier
#   {{NETWORK_NAME}} - Docker network name
#   {{DB_NAME}} - Database name
#   {{DB_USER}} - Database user
# ============================================================================

# =============================================================================
# APP SERVICE EXAMPLE (Issue #30 - Claude Credentials)
# =============================================================================
# When adding your app service, include the credentials mount:
#
#   app:
#     volumes:
#       - .:/workspace:cached
#       - ~/.claude:/tmp/host-claude:ro              # Host Claude config (read-only)
#       - ~/.config/claude-env:/tmp/host-env:ro      # Environment secrets (optional)
#       - ~/.config/gh:/tmp/host-gh:ro               # GitHub CLI config (optional)
#
# Then use .devcontainer/setup-claude-credentials.sh in postCreateCommand
# =============================================================================

services:
  # ===SECTION_START:postgres===
  postgres:
    image: postgres:16-bookworm
    container_name: demo-app-postgres
    restart: unless-stopped
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-{{DB_NAME}}}
      POSTGRES_USER: ${POSTGRES_USER:-{{DB_USER}}}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-devpassword}
      POSTGRES_INITDB_ARGS: "--encoding=UTF8 --locale=C"
    ports:
      - "${POSTGRES_PORT:-5432}:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./db-init:/docker-entrypoint-initdb.d:ro
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-{{DB_USER}}} -d ${POSTGRES_DB:-{{DB_NAME}}}"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    networks:
      - default
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 512M
  # ===SECTION_END:postgres===

  # ===SECTION_START:mysql===
  mysql:
    image: mysql:8.0
    container_name: demo-app-mysql
    restart: unless-stopped
    environment:
      MYSQL_DATABASE: ${MYSQL_DATABASE:-{{DB_NAME}}}
      MYSQL_USER: ${MYSQL_USER:-{{DB_USER}}}
      MYSQL_PASSWORD: ${MYSQL_PASSWORD:-devpassword}
      MYSQL_ROOT_PASSWORD: ${MYSQL_ROOT_PASSWORD:-rootpassword}
      MYSQL_CHARSET: utf8mb4
      MYSQL_COLLATION: utf8mb4_unicode_ci
    ports:
      - "${MYSQL_PORT:-3306}:3306"
    volumes:
      - mysql_data:/var/lib/mysql
      - ./mysql-init:/docker-entrypoint-initdb.d:ro
    command: --default-authentication-plugin=mysql_native_password
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost", "-u", "root", "-p${MYSQL_ROOT_PASSWORD:-rootpassword}"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    networks:
      - default
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 512M
  # ===SECTION_END:mysql===

  # ===SECTION_START:mongodb===
  mongodb:
    image: mongo:7
    container_name: demo-app-mongodb
    restart: unless-stopped
    environment:
      MONGO_INITDB_ROOT_USERNAME: ${MONGO_USER:-admin}
      MONGO_INITDB_ROOT_PASSWORD: ${MONGO_PASSWORD:-devpassword}
      MONGO_INITDB_DATABASE: ${MONGO_DATABASE:-{{DB_NAME}}}
    ports:
      - "${MONGO_PORT:-27017}:27017"
    volumes:
      - mongodb_data:/data/db
      - mongodb_config:/data/configdb
      - ./mongo-init:/docker-entrypoint-initdb.d:ro
    healthcheck:
      test: ["CMD", "mongosh", "--eval", "db.adminCommand('ping')"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    networks:
      - default
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 512M
  # ===SECTION_END:mongodb===

  # ===SECTION_START:redis===
  redis:
    image: redis:7-alpine
    container_name: demo-app-redis
    restart: unless-stopped
    command: redis-server --appendonly yes --requirepass ${REDIS_PASSWORD:-devpassword}
    ports:
      - "${REDIS_PORT:-6379}:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    networks:
      - default
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G
        reservations:
          cpus: '0.25'
          memory: 256M
  # ===SECTION_END:redis===

  # ===SECTION_START:rabbitmq===
  rabbitmq:
    image: rabbitmq:3.13-management
    container_name: demo-app-rabbitmq
    restart: unless-stopped
    environment:
      RABBITMQ_DEFAULT_USER: ${RABBITMQ_USER:-guest}
      RABBITMQ_DEFAULT_PASS: ${RABBITMQ_PASSWORD:-guest}
      RABBITMQ_DEFAULT_VHOST: ${RABBITMQ_VHOST:-/}
    ports:
      - "${RABBITMQ_PORT:-5672}:5672"
      - "${RABBITMQ_MGMT_PORT:-15672}:15672"
    volumes:
      - rabbitmq_data:/var/lib/rabbitmq
    healthcheck:
      test: ["CMD", "rabbitmqctl", "status"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    networks:
      - default
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
  # ===SECTION_END:rabbitmq===

  # ===SECTION_START:kafka===
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: demo-app-zookeeper
    restart: unless-stopped
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_SYNC_LIMIT: 2
    volumes:
      - zookeeper_data:/var/lib/zookeeper/data
      - zookeeper_logs:/var/lib/zookeeper/log
    networks:
      - default
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: demo-app-kafka
    restart: unless-stopped
    depends_on:
      - zookeeper
    ports:
      - "${KAFKA_PORT:-9092}:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    volumes:
      - kafka_data:/var/lib/kafka/data
    healthcheck:
      test: ["CMD", "kafka-broker-api-versions", "--bootstrap-server", "localhost:9092"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    networks:
      - default
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 1G
  # ===SECTION_END:kafka===

  # ===SECTION_START:elasticsearch===
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    container_name: demo-app-elasticsearch
    restart: unless-stopped
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
      - bootstrap.memory_lock=true
    ulimits:
      memlock:
        soft: -1
        hard: -1
    ports:
      - "${ELASTICSEARCH_PORT:-9200}:9200"
      - "${ELASTICSEARCH_TRANSPORT_PORT:-9300}:9300"
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
    healthcheck:
      test: ["CMD-SHELL", "curl -s http://localhost:9200/_cluster/health | grep -vq '\"status\":\"red\"'"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    networks:
      - default
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 1G
  # ===SECTION_END:elasticsearch===

  # ===SECTION_START:minio===
  minio:
    image: minio/minio:latest
    container_name: demo-app-minio
    restart: unless-stopped
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: ${MINIO_USER:-minioadmin}
      MINIO_ROOT_PASSWORD: ${MINIO_PASSWORD:-minioadmin}
    ports:
      - "${MINIO_PORT:-9000}:9000"
      - "${MINIO_CONSOLE_PORT:-9001}:9001"
    volumes:
      - minio_data:/data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3
      start_period: 20s
    networks:
      - default
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 512M
  # ===SECTION_END:minio===

  # ===SECTION_START:nginx===
  nginx:
    image: nginx:1.25-bookworm
    container_name: demo-app-nginx
    restart: unless-stopped
    ports:
      - "${NGINX_PORT:-80}:80"
      - "${NGINX_SSL_PORT:-443}:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx-html:/usr/share/nginx/html:ro
      - ./certs:/etc/nginx/certs:ro
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    networks:
      - default
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 128M
  # ===SECTION_END:nginx===

  # ===SECTION_START:prometheus===
  prometheus:
    image: prom/prometheus:v2.47.0
    container_name: demo-app-prometheus
    restart: unless-stopped
    ports:
      - "${PROMETHEUS_PORT:-9090}:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=30d'
      - '--web.enable-lifecycle'
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    networks:
      - default
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G
        reservations:
          cpus: '0.25'
          memory: 512M
  # ===SECTION_END:prometheus===

  # ===SECTION_START:grafana===
  grafana:
    image: grafana/grafana:10.2.0
    container_name: demo-app-grafana
    restart: unless-stopped
    ports:
      - "${GRAFANA_PORT:-3000}:3000"
    environment:
      GF_SECURITY_ADMIN_USER: ${GRAFANA_USER:-admin}
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_PASSWORD:-admin}
      GF_INSTALL_PLUGINS: ${GRAFANA_PLUGINS:-}
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning:ro
    depends_on:
      - prometheus
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    networks:
      - default
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
  # ===SECTION_END:grafana===

  # ===SECTION_START:jaeger===
  jaeger:
    image: jaegertracing/all-in-one:1.51
    container_name: demo-app-jaeger
    restart: unless-stopped
    ports:
      - "${JAEGER_UI_PORT:-16686}:16686"
      - "${JAEGER_COLLECTOR_PORT:-14268}:14268"
      - "${JAEGER_COLLECTOR_GRPC_PORT:-14250}:14250"
      - "${JAEGER_AGENT_PORT:-6831}:6831/udp"
      - "${JAEGER_AGENT_COMPACT_PORT:-6832}:6832/udp"
    environment:
      COLLECTOR_OTLP_ENABLED: "true"
      SPAN_STORAGE_TYPE: badger
      BADGER_EPHEMERAL: "false"
      BADGER_DIRECTORY_VALUE: /badger/data
      BADGER_DIRECTORY_KEY: /badger/key
    volumes:
      - jaeger_data:/badger
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:14269/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    networks:
      - default
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G
        reservations:
          cpus: '0.25'
          memory: 256M
  # ===SECTION_END:jaeger===

  # ===SECTION_START:ollama===
  ollama:
    image: ollama/ollama:latest
    container_name: demo-app-ollama
    restart: unless-stopped
    ports:
      - "${OLLAMA_PORT:-11434}:11434"
    volumes:
      - ollama_data:/root/.ollama
    environment:
      OLLAMA_HOST: "0.0.0.0"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
        limits:
          memory: 8G
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    networks:
      - default
  # ===SECTION_END:ollama===

  # ===SECTION_START:pgadmin===
  pgadmin:
    image: dpage/pgadmin4:latest
    container_name: demo-app-pgadmin
    restart: unless-stopped
    environment:
      PGADMIN_DEFAULT_EMAIL: ${PGADMIN_EMAIL:-admin@example.com}
      PGADMIN_DEFAULT_PASSWORD: ${PGADMIN_PASSWORD:-admin}
      PGADMIN_CONFIG_SERVER_MODE: "False"
    ports:
      - "${PGADMIN_PORT:-5050}:80"
    volumes:
      - pgadmin_data:/var/lib/pgadmin
    depends_on:
      - postgres
    networks:
      - default
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
  # ===SECTION_END:pgadmin===

  # ===SECTION_START:redis_commander===
  redis-commander:
    image: rediscommander/redis-commander:latest
    container_name: demo-app-redis-commander
    restart: unless-stopped
    environment:
      REDIS_HOSTS: local:redis:6379:0:${REDIS_PASSWORD:-devpassword}
    ports:
      - "${REDIS_COMMANDER_PORT:-8081}:8081"
    depends_on:
      - redis
    networks:
      - default
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 128M
  # ===SECTION_END:redis_commander===

# ===SECTION_START:volumes===
volumes:
  # ===SECTION_START:volume_postgres===
  postgres_data:
    driver: local
  # ===SECTION_END:volume_postgres===

  # ===SECTION_START:volume_mysql===
  mysql_data:
    driver: local
  # ===SECTION_END:volume_mysql===

  # ===SECTION_START:volume_mongodb===
  mongodb_data:
    driver: local
  mongodb_config:
    driver: local
  # ===SECTION_END:volume_mongodb===

  # ===SECTION_START:volume_redis===
  redis_data:
    driver: local
  # ===SECTION_END:volume_redis===

  # ===SECTION_START:volume_rabbitmq===
  rabbitmq_data:
    driver: local
  # ===SECTION_END:volume_rabbitmq===

  # ===SECTION_START:volume_kafka===
  zookeeper_data:
    driver: local
  zookeeper_logs:
    driver: local
  kafka_data:
    driver: local
  # ===SECTION_END:volume_kafka===

  # ===SECTION_START:volume_elasticsearch===
  elasticsearch_data:
    driver: local
  # ===SECTION_END:volume_elasticsearch===

  # ===SECTION_START:volume_minio===
  minio_data:
    driver: local
  # ===SECTION_END:volume_minio===

  # ===SECTION_START:volume_prometheus===
  prometheus_data:
    driver: local
  # ===SECTION_END:volume_prometheus===

  # ===SECTION_START:volume_grafana===
  grafana_data:
    driver: local
  # ===SECTION_END:volume_grafana===

  # ===SECTION_START:volume_jaeger===
  jaeger_data:
    driver: local
  # ===SECTION_END:volume_jaeger===

  # ===SECTION_START:volume_ollama===
  ollama_data:
    driver: local
  # ===SECTION_END:volume_ollama===

  # ===SECTION_START:volume_pgadmin===
  pgadmin_data:
    driver: local
  # ===SECTION_END:volume_pgadmin===
# ===SECTION_END:volumes===

networks:
  default:
    name: {{NETWORK_NAME}}
    driver: bridge
